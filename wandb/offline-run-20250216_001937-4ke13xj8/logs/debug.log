2025-02-16 00:19:37,184 INFO    MainThread:3850031 [wandb_setup.py:_flush():76] Current SDK version is 0.17.5
2025-02-16 00:19:37,184 INFO    MainThread:3850031 [wandb_setup.py:_flush():76] Configure stats pid to 3850031
2025-02-16 00:19:37,184 INFO    MainThread:3850031 [wandb_setup.py:_flush():76] Loading settings from /home/wanghuiy/.config/wandb/settings
2025-02-16 00:19:37,184 INFO    MainThread:3850031 [wandb_setup.py:_flush():76] Loading settings from /gpfs/home/wanghuiy/RL-Chemist/wandb/settings
2025-02-16 00:19:37,184 INFO    MainThread:3850031 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-02-16 00:19:37,184 INFO    MainThread:3850031 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-02-16 00:19:37,184 INFO    MainThread:3850031 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'Train_reach.py', 'program_abspath': '/gpfs/home/wanghuiy/RL-Chemist/Train_reach.py', 'program': '/gpfs/home/wanghuiy/RL-Chemist/Train_reach.py'}
2025-02-16 00:19:37,184 INFO    MainThread:3850031 [wandb_init.py:_log_setup():529] Logging user logs to /gpfs/home/wanghuiy/RL-Chemist/wandb/offline-run-20250216_001937-4ke13xj8/logs/debug.log
2025-02-16 00:19:37,184 INFO    MainThread:3850031 [wandb_init.py:_log_setup():530] Logging internal logs to /gpfs/home/wanghuiy/RL-Chemist/wandb/offline-run-20250216_001937-4ke13xj8/logs/debug-internal.log
2025-02-16 00:19:37,184 INFO    MainThread:3850031 [wandb_init.py:init():569] calling init triggers
2025-02-16 00:19:37,184 INFO    MainThread:3850031 [wandb_init.py:init():576] wandb.init called with sweep_config: {}
config: {'policy_type': 'PPO', 'name': '2025_02_16_00_19_363', 'total_timesteps': 3500000, 'env_name': 'UR10eReach1C-v1', 'dense_units': 512, 'activation': 'relu', 'max_episode_steps': 250, 'seed': 3, 'entropy': 0.01, 'lr': 0.0003, 'CR': 0.1, 'num_envs': 4, 'loaded_model': '2024_09_25_13_42_113'}
2025-02-16 00:19:37,184 INFO    MainThread:3850031 [wandb_init.py:init():619] starting backend
2025-02-16 00:19:37,184 INFO    MainThread:3850031 [wandb_init.py:init():623] setting up manager
2025-02-16 00:19:37,187 INFO    MainThread:3850031 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: fork
2025-02-16 00:19:37,188 INFO    MainThread:3850031 [wandb_init.py:init():631] backend started and connected
2025-02-16 00:19:37,194 INFO    MainThread:3850031 [wandb_init.py:init():720] updated telemetry
2025-02-16 00:19:37,201 INFO    MainThread:3850031 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2025-02-16 00:19:37,205 INFO    MainThread:3850031 [wandb_init.py:init():804] starting run threads in backend
2025-02-16 00:19:41,398 INFO    MainThread:3850031 [wandb_run.py:_console_start():2413] atexit reg
2025-02-16 00:19:41,398 INFO    MainThread:3850031 [wandb_run.py:_redirect():2255] redirect: wrap_raw
2025-02-16 00:19:41,398 INFO    MainThread:3850031 [wandb_run.py:_redirect():2320] Wrapping output streams.
2025-02-16 00:19:41,398 INFO    MainThread:3850031 [wandb_run.py:_redirect():2345] Redirects installed.
2025-02-16 00:19:41,400 INFO    MainThread:3850031 [wandb_init.py:init():847] run started, returning control to user process
2025-02-16 00:19:46,869 INFO    MainThread:3850031 [wandb_run.py:_tensorboard_callback():1544] tensorboard callback: runs/2025_02_16_00_19_363/PPO_1, True
2025-02-16 00:19:46,882 INFO    MainThread:3850031 [wandb_watch.py:watch():51] Watching
2025-02-16 00:19:46,883 INFO    MainThread:3850031 [wandb_run.py:_config_callback():1382] config_cb None None {'algo': 'PPO', 'policy_class': "<class '__main__.CustomMultiInputPolicy'>", 'device': 'cuda', 'verbose': 0, 'policy_kwargs': '{}', 'num_timesteps': 0, '_total_timesteps': 3500000, '_num_timesteps_at_start': 0, 'action_noise': 'None', 'start_time': 1739683186785769605, 'learning_rate': '<function linear_schedule.<locals>.func at 0x7fb7a1405a20>', 'tensorboard_log': 'runs/2025_02_16_00_19_363', '_last_obs': "{'image': array([[[[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        ...,\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]]],\n\n\n       [[[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        ...,\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]]],\n\n\n       [[[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        ...,\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]]],\n\n\n       [[[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        ...,\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         ...,\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [0., 0., 1.]]]], dtype=float32), 'vector': array([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.7945e+00, -2.1094e+00,\n         2.6301e+00,  3.1024e+00, -1.5595e+00,  0.0000e+00,  2.5455e-03,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00, -1.0000e+01],\n       [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8213e+00, -2.1186e+00,\n         2.5632e+00,  3.0766e+00, -1.5380e+00,  0.0000e+00,  2.5455e-03,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00, -1.0000e+01],\n       [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.7619e+00, -2.0925e+00,\n         2.6529e+00,  3.0330e+00, -1.5033e+00,  0.0000e+00,  2.5455e-03,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00, -1.0000e+01],\n       [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.7792e+00, -2.0695e+00,\n         2.6251e+00,  3.1192e+00, -1.5766e+00,  0.0000e+00,  2.5455e-03,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00, -1.0000e+01]], dtype=float32)}", '_last_episode_starts': '[ True  True  True  True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.vec_frame_stack.VecFrameStack object at 0x7fb470234820>', '_vec_normalize_env': 'None', 'observation_space': "Dict('image': Box(0.0, 255.0, (120, 212, 3), float32), 'vector': Box(-10.0, 10.0, (42,), float32))", 'action_space': 'Box(-1.0, 1.0, (7,), float32)', 'n_envs': 4, 'n_steps': 2048, 'gamma': 0.99, 'gae_lambda': 0.95, 'ent_coef': 0.01, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'rollout_buffer_class': "<class 'stable_baselines3.common.buffers.DictRolloutBuffer'>", 'rollout_buffer_kwargs': '{}', 'batch_size': 64, 'n_epochs': 10, 'clip_range': '<function get_schedule_fn.<locals>.<lambda> at 0x7fb1ed1f1ab0>', 'clip_range_vf': 'None', 'normalize_advantage': 'True', 'target_kl': 'None', 'lr_schedule': '<function get_schedule_fn.<locals>.<lambda> at 0x7fb470137eb0>', 'rollout_buffer': '<stable_baselines3.common.buffers.DictRolloutBuffer object at 0x7fb4701545b0>', 'policy': 'CustomMultiInputPolicy(\n  (features_extractor): CustomDictFeaturesExtractor(\n    (cnn): Sequential(\n      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n    )\n    (mlp): Linear(in_features=42, out_features=512, bias=True)\n  )\n  (pi_features_extractor): CustomDictFeaturesExtractor(\n    (cnn): Sequential(\n      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n    )\n    (mlp): Linear(in_features=42, out_features=512, bias=True)\n  )\n  (vf_features_extractor): CustomDictFeaturesExtractor(\n    (cnn): Sequential(\n      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n    )\n    (mlp): Linear(in_features=42, out_features=512, bias=True)\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=25472, out_features=512, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=512, out_features=512, bias=True)\n      (3): Tanh()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=25472, out_features=512, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=512, out_features=512, bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=512, out_features=7, bias=True)\n  (value_net): Linear(in_features=512, out_features=1, bias=True)\n)', '_logger': '<stable_baselines3.common.logger.Logger object at 0x7fb4702341f0>'}
